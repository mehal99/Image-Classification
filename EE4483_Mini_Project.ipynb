{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:53:09.515679Z",
     "iopub.status.busy": "2021-11-12T05:53:09.515151Z",
     "iopub.status.idle": "2021-11-12T05:53:15.227777Z",
     "shell.execute_reply": "2021-11-12T05:53:15.226639Z",
     "shell.execute_reply.started": "2021-11-12T05:53:09.515587Z"
    },
    "id": "Ktu4u-0ycem9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, cv2, random\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from random import shuffle \n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from typing import List\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from numpy.random import permutation\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialze the path to directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:53:20.765766Z",
     "iopub.status.busy": "2021-11-12T05:53:20.765246Z",
     "iopub.status.idle": "2021-11-12T05:53:20.773739Z",
     "shell.execute_reply": "2021-11-12T05:53:20.773044Z",
     "shell.execute_reply.started": "2021-11-12T05:53:20.765729Z"
    },
    "id": "z-pvb0k_DQn1"
   },
   "outputs": [],
   "source": [
    "base_dir = '../input/ee4483/datasets'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "train_cat_dir = os.path.join(train_dir, 'cat')\n",
    "train_dog_dir = os.path.join(train_dir, 'dog')\n",
    "\n",
    "val_cat_dir = os.path.join(val_dir, 'cat')\n",
    "val_dog_dir = os.path.join(val_dir, 'dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04HWsRn8fKpT"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ak1EX3v9PBgC"
   },
   "source": [
    "Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:53:25.468707Z",
     "iopub.status.busy": "2021-11-12T05:53:25.46803Z",
     "iopub.status.idle": "2021-11-12T05:53:26.821977Z",
     "shell.execute_reply": "2021-11-12T05:53:26.821247Z",
     "shell.execute_reply.started": "2021-11-12T05:53:25.46867Z"
    },
    "id": "iUNlkqfAfJ-X",
    "outputId": "48d15000-b7bd-4d62-f026-3c7a61a50cd0"
   },
   "outputs": [],
   "source": [
    "print('Number of Images of cat for training: ', len(os.listdir(train_cat_dir)))\n",
    "print('Number of Images of dog for training: ', len(os.listdir(train_dog_dir)))\n",
    "print('Number of Images of cat for validation: ', len(os.listdir(val_cat_dir)))\n",
    "print('Number of Images of dog for validation: ', len(os.listdir(val_dog_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:53:28.690743Z",
     "iopub.status.busy": "2021-11-12T05:53:28.6901Z",
     "iopub.status.idle": "2021-11-12T05:53:29.053026Z",
     "shell.execute_reply": "2021-11-12T05:53:29.052345Z",
     "shell.execute_reply.started": "2021-11-12T05:53:28.690706Z"
    },
    "id": "nFwWD5yShX0y"
   },
   "outputs": [],
   "source": [
    "class_names = ['cat', 'dog']\n",
    "train_count = [len(os.listdir(train_cat_dir)), len(os.listdir(train_dog_dir))]\n",
    "val_count = [len(os.listdir(val_cat_dir)), len(os.listdir(val_dog_dir))]\n",
    "\n",
    "X_axis = np.arange(len(class_names))\n",
    "  \n",
    "plt.bar(X_axis - 0.2, train_count, 0.4, label = 'Train')\n",
    "plt.bar(X_axis + 0.2, val_count, 0.4, label = 'Validation')\n",
    "  \n",
    "plt.xticks(X_axis, class_names)\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.title(\"Number of images for training and validation for each class\")\n",
    "plt.legend(bbox_to_anchor = (1.28, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:53:32.791503Z",
     "iopub.status.busy": "2021-11-12T05:53:32.791229Z",
     "iopub.status.idle": "2021-11-12T05:53:33.124111Z",
     "shell.execute_reply": "2021-11-12T05:53:33.123167Z",
     "shell.execute_reply.started": "2021-11-12T05:53:32.791473Z"
    }
   },
   "outputs": [],
   "source": [
    "train = len(os.listdir(train_cat_dir))+len(os.listdir(train_dog_dir))\n",
    "val = len(os.listdir(val_cat_dir))+len(os.listdir(val_dog_dir))\n",
    "test = len(os.listdir(test_dir))\n",
    "\n",
    "x = [\"train\", \"val\", \"test\"]\n",
    "height = [train, val, test]\n",
    "plt.bar(x = x, height = height)\n",
    "plt.title(\"Dataset distribution\")\n",
    "plt.xlabel(\"Sets\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7aZaeTjPF9E"
   },
   "source": [
    "Show Images from training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:53:37.990131Z",
     "iopub.status.busy": "2021-11-12T05:53:37.989839Z",
     "iopub.status.idle": "2021-11-12T05:53:56.786393Z",
     "shell.execute_reply": "2021-11-12T05:53:56.785604Z",
     "shell.execute_reply.started": "2021-11-12T05:53:37.990101Z"
    },
    "id": "i1ka_nMqOcMV"
   },
   "outputs": [],
   "source": [
    "train_dataset = image_dataset_from_directory(train_dir,\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=32,\n",
    "                                             image_size=(224, 224),\n",
    "                                             seed = 123)\n",
    "validation_dataset = image_dataset_from_directory(val_dir,\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=32,\n",
    "                                                  image_size=(224,224),\n",
    "                                                  seed = 123)\n",
    "class_names = train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:54:11.690447Z",
     "iopub.status.busy": "2021-11-12T05:54:11.690095Z",
     "iopub.status.idle": "2021-11-12T05:54:11.701824Z",
     "shell.execute_reply": "2021-11-12T05:54:11.701065Z",
     "shell.execute_reply.started": "2021-11-12T05:54:11.690408Z"
    },
    "id": "wKr-sIdEpIe0"
   },
   "outputs": [],
   "source": [
    "def plot_images(dataset):\n",
    "    #This function plots the images from training or validation datasets\n",
    "    class_names = dataset.class_names\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(class_names[labels[i]])\n",
    "            plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After data loading, we explore the data by visualizing some images from the training and validation sets\n",
    "by plotting some sample images and their corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:54:20.565745Z",
     "iopub.status.busy": "2021-11-12T05:54:20.565176Z",
     "iopub.status.idle": "2021-11-12T05:54:21.918078Z",
     "shell.execute_reply": "2021-11-12T05:54:21.917392Z",
     "shell.execute_reply.started": "2021-11-12T05:54:20.565697Z"
    },
    "id": "LFggcwpIOsXB"
   },
   "outputs": [],
   "source": [
    "plot_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:54:25.27394Z",
     "iopub.status.busy": "2021-11-12T05:54:25.273665Z",
     "iopub.status.idle": "2021-11-12T05:54:27.170822Z",
     "shell.execute_reply": "2021-11-12T05:54:27.170123Z",
     "shell.execute_reply.started": "2021-11-12T05:54:25.273902Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_images(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER1tdLqUPIQ8"
   },
   "source": [
    "# Define Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T23:30:25.257963Z",
     "iopub.status.busy": "2021-11-11T23:30:25.257239Z",
     "iopub.status.idle": "2021-11-11T23:30:25.268107Z",
     "shell.execute_reply": "2021-11-11T23:30:25.267382Z",
     "shell.execute_reply.started": "2021-11-11T23:30:25.257923Z"
    },
    "id": "nwk4ulQNtzK3"
   },
   "outputs": [],
   "source": [
    "def build_baseline_CNN():\n",
    "    #This function is used to build the baseline CNN model\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:54:29.220439Z",
     "iopub.status.busy": "2021-11-12T05:54:29.219959Z",
     "iopub.status.idle": "2021-11-12T05:54:29.229266Z",
     "shell.execute_reply": "2021-11-12T05:54:29.22856Z",
     "shell.execute_reply.started": "2021-11-12T05:54:29.220405Z"
    },
    "id": "jzFjr9_8xqb6"
   },
   "outputs": [],
   "source": [
    "def plot_result(history, k=0):\n",
    "    #This function is used to plot the learning curves\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    #Plot accuracy \n",
    "    plt.plot(epochs, acc, label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.margins(0.05, tight=True)\n",
    "    plt.legend(loc='lower right')\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename +'_'+str(k)+'_acc_plot.png')\n",
    "    plt.figure()\n",
    "\n",
    "    #Plot Loss\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(epochs, loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.margins(0.05, tight=True)\n",
    "    plt.legend(loc='upper right')\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    plt.savefig(filename +'_'+str(k)+'_loss_plot.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSxxmdibP-c5"
   },
   "source": [
    "Run Basline Model Without Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T23:30:32.529038Z",
     "iopub.status.busy": "2021-11-11T23:30:32.528179Z",
     "iopub.status.idle": "2021-11-11T23:30:32.537734Z",
     "shell.execute_reply": "2021-11-11T23:30:32.536491Z",
     "shell.execute_reply.started": "2021-11-11T23:30:32.528983Z"
    },
    "id": "ROP1zQ3hTd0C"
   },
   "outputs": [],
   "source": [
    "def run_baseline():\n",
    "    #This function is used to train and evaluate the baseline CNN model\n",
    "    \n",
    "    #build the model\n",
    "    model = build_baseline_CNN() \n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterators\n",
    "    train_ds = datagen.flow_from_directory(train_dir,\n",
    "                                           class_mode='binary', batch_size=32, target_size=(224, 224))\n",
    "    val_ds = datagen.flow_from_directory(val_dir,\n",
    "                                         class_mode='binary', batch_size=32, target_size=(224, 224))\n",
    "    #compile the model\n",
    "    model.compile(optimizer=Adam(),\n",
    "              loss=tf.keras.losses.binary_crossentropy,\n",
    "              metrics=['accuracy'])  \n",
    "    model.summary()\n",
    "    # fit the model\n",
    "    history = model.fit(train_ds, steps_per_epoch=len(train_ds),\n",
    "                        validation_data=val_ds, validation_steps=len(val_ds), epochs=20)\n",
    "    model.save('Baseline_CNN_w/o_aug.h5')\n",
    "    # evaluate the model\n",
    "    score1 = model.evaluate(train_ds, verbose =0)\n",
    "    score2 = model.evaluate(val_ds, verbose=0)\n",
    "    print('Training Accuracy  : %1.2f%%     Training loss  : %1.6f'%(score1[1]*100,score1[0]))\n",
    "    print('Validation Accuracy: %1.2f%%     Validation loss: %1.6f'%(score2[1]*100,score2[0]))\n",
    "    # plot the learning curves\n",
    "    plot_result(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-11T23:30:53.21721Z",
     "iopub.status.busy": "2021-11-11T23:30:53.216686Z"
    },
    "id": "OgXHLOmpQjli"
   },
   "outputs": [],
   "source": [
    "run_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "faJC6zDF6JGu"
   },
   "source": [
    "# Data Loading and Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:54:57.466105Z",
     "iopub.status.busy": "2021-11-12T05:54:57.465839Z",
     "iopub.status.idle": "2021-11-12T05:54:57.473666Z",
     "shell.execute_reply": "2021-11-12T05:54:57.47287Z",
     "shell.execute_reply.started": "2021-11-12T05:54:57.466076Z"
    },
    "id": "SHPpC7HLCb-2"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    #This function is used to load data and perform preprocessing\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                     rotation_range = 40, \n",
    "                                     width_shift_range = 0.2, \n",
    "                                     height_shift_range = 0.2, \n",
    "                                     shear_range = 0.2, \n",
    "                                     zoom_range = 0.2, \n",
    "                                     horizontal_flip = True)\n",
    "\n",
    "    validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "    train_dataset = train_datagen.flow_from_directory(train_dir,\n",
    "                                                   target_size=(224, 224),\n",
    "                                                   batch_size=32,\n",
    "                                                   class_mode='binary',\n",
    "                                                   seed =123)\n",
    "    validation_dataset = validation_datagen.flow_from_directory(val_dir,\n",
    "                                                      target_size=(224, 224),\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='binary',\n",
    "                                                      seed =123)\n",
    "    return train_dataset, validation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize images after augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:02.890909Z",
     "iopub.status.busy": "2021-11-12T05:55:02.890387Z",
     "iopub.status.idle": "2021-11-12T05:55:07.321404Z",
     "shell.execute_reply": "2021-11-12T05:55:07.320565Z",
     "shell.execute_reply.started": "2021-11-12T05:55:02.890872Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, val_ds = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:08.188944Z",
     "iopub.status.busy": "2021-11-12T05:55:08.188456Z",
     "iopub.status.idle": "2021-11-12T05:55:09.688285Z",
     "shell.execute_reply": "2021-11-12T05:55:09.68763Z",
     "shell.execute_reply.started": "2021-11-12T05:55:08.188909Z"
    }
   },
   "outputs": [],
   "source": [
    "x= train_ds.next()\n",
    "plt.figure(figsize=(10, 10))\n",
    "image=x[0]\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(image[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_wui49qlHAm"
   },
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:14.011216Z",
     "iopub.status.busy": "2021-11-12T05:55:14.010314Z",
     "iopub.status.idle": "2021-11-12T05:55:14.019922Z",
     "shell.execute_reply": "2021-11-12T05:55:14.01895Z",
     "shell.execute_reply.started": "2021-11-12T05:55:14.011155Z"
    },
    "id": "zWnNgDlPPkIp"
   },
   "outputs": [],
   "source": [
    "def build_model_CNN():  \n",
    "    #This function is used to build the CNN model with dropout regularization\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:34.079241Z",
     "iopub.status.busy": "2021-11-12T05:55:34.078963Z",
     "iopub.status.idle": "2021-11-12T05:55:34.085678Z",
     "shell.execute_reply": "2021-11-12T05:55:34.084673Z",
     "shell.execute_reply.started": "2021-11-12T05:55:34.079205Z"
    },
    "id": "J4ELIK1ZCy9F"
   },
   "outputs": [],
   "source": [
    "def build_model_VGG16():\n",
    "    #This function is used to build the model with a VGG-16 pretrained feature extraction backbone\n",
    "    \n",
    "    model = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # loaded layers set to be not trainable\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # addition of classification layers\n",
    "    flat1 = Flatten()(model.layers[-1].output)\n",
    "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "    output = Dense(1, activation='sigmoid')(class1)\n",
    "    \n",
    "    # define the model\n",
    "    model = Model(inputs=model.inputs, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkph7ZWKlOwX"
   },
   "source": [
    "# Training for Different Parameters and Log the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3a0tbC5ah4V"
   },
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:42.85996Z",
     "iopub.status.busy": "2021-11-12T05:55:42.859697Z",
     "iopub.status.idle": "2021-11-12T05:55:42.866628Z",
     "shell.execute_reply": "2021-11-12T05:55:42.865916Z",
     "shell.execute_reply.started": "2021-11-12T05:55:42.85993Z"
    },
    "id": "duRfSqX0Bu4Y"
   },
   "outputs": [],
   "source": [
    "def train_fn(model, hp:dict, train_dataset, validation_dataset, k) -> dict:\n",
    "    #This function runs the training loop and tests the model on validation data\n",
    "    \n",
    "    checkpointer = ModelCheckpoint(filepath = \"weights_best_hp_\"+str(k)+\".h5\", save_best_only = True, save_weights_only = True)\n",
    "    \n",
    "    history = model.fit(train_dataset,\n",
    "                          validation_data=validation_dataset,\n",
    "                          epochs=hp['epoch'],\n",
    "                          callbacks = [checkpointer])\n",
    "  \n",
    "    model.save('./VGG_hp_'+str(k)+'.h5') #change to model.save('./CNN_hp_'+str(k)+'.h5') when using CNN model\n",
    "  \n",
    "    #Visualize training result\n",
    "    plot_result(history,k)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_7sLbOLarM3"
   },
   "source": [
    "Log Results for each configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:47.67314Z",
     "iopub.status.busy": "2021-11-12T05:55:47.672609Z",
     "iopub.status.idle": "2021-11-12T05:55:47.67819Z",
     "shell.execute_reply": "2021-11-12T05:55:47.677442Z",
     "shell.execute_reply.started": "2021-11-12T05:55:47.673102Z"
    },
    "id": "aXUsqslICszp"
   },
   "outputs": [],
   "source": [
    "def parse_results(hp, score1, score2):\n",
    "    # This function logs the results of the parameter configuration \n",
    "    \n",
    "    data = [hp['epoch'], hp['optimizer'], hp['lr'], score1[0], score1[1], score2[0], score2[1]]\n",
    "    df = pd.Series(data).to_frame()   \n",
    "    filename = './VGG_Records.csv'  #change to filename = './CNN_Records.csv' when used with CNN model\n",
    "    with open(filename, 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iei7toebavpq"
   },
   "source": [
    "Training Engine for different parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:55:51.424056Z",
     "iopub.status.busy": "2021-11-12T05:55:51.423483Z",
     "iopub.status.idle": "2021-11-12T05:55:51.433878Z",
     "shell.execute_reply": "2021-11-12T05:55:51.433094Z",
     "shell.execute_reply.started": "2021-11-12T05:55:51.424018Z"
    },
    "id": "PzUqMqFnCkwh"
   },
   "outputs": [],
   "source": [
    "def run_experiments(exp_hp: List[dict]):\n",
    "    #This function is used to run different parameter configurations and to log the results\n",
    "    k = 0\n",
    "    for hp in exp_hp:\n",
    "        tf.random.set_seed(123)\n",
    "\n",
    "        # Create the datasets\n",
    "        train_dataset, validation_dataset = load_data()\n",
    "        \n",
    "        #build model\n",
    "        model = build_model_VGG16() #change to model = build_model_CNN() if CNN model is to be used \n",
    "        model.summary()\n",
    "        \n",
    "        #Assign optimizer \n",
    "        if hp['optimizer'] == 'Adam':\n",
    "            opt = Adam(learning_rate=hp['lr'])\n",
    "        elif hp['optimizer'] == 'SGD':\n",
    "            opt = SGD(learning_rate=hp['lr'], momentum=0.9)\n",
    "        else:\n",
    "            opt = RMSprop(learning_rate=hp['lr'])\n",
    "            \n",
    "        #compile model\n",
    "        model.compile(optimizer=opt,\n",
    "                      loss=tf.keras.losses.binary_crossentropy,\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        print('Parameter set: ', hp)\n",
    "        # Call the training function\n",
    "        history = train_fn(model, hp, train_dataset, validation_dataset, k+1)\n",
    "        #Evaluate the model\n",
    "        score1 = model.evaluate(train_dataset, verbose =0)\n",
    "        score2 = model.evaluate(validation_dataset, verbose=0)\n",
    "        print('Training Accuracy  : %1.2f%%     Training loss  : %1.6f'%(score1[1]*100,score1[0]))\n",
    "        print('Validation Accuracy: %1.2f%%     Validation loss: %1.6f'%(score2[1]*100,score2[0]))\n",
    "        #Log Results\n",
    "        parse_results(hp, score1, score2) \n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define different parameter configurations used with each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:56:34.519395Z",
     "iopub.status.busy": "2021-11-12T05:56:34.51882Z",
     "iopub.status.idle": "2021-11-12T05:56:34.527607Z",
     "shell.execute_reply": "2021-11-12T05:56:34.526863Z",
     "shell.execute_reply.started": "2021-11-12T05:56:34.519356Z"
    },
    "id": "8v3QqhQSC4GE"
   },
   "outputs": [],
   "source": [
    "hps = [{\n",
    "          \"epoch\": 10,\n",
    "          \"optimizer\": 'Adam',\n",
    "          \"lr\": 0.00001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 10,\n",
    "          \"optimizer\": 'Adam',\n",
    "          \"lr\": 0.001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 10,\n",
    "          \"optimizer\": 'SGD',\n",
    "          \"lr\": 0.001\n",
    "       }, \n",
    "       {\n",
    "          \"epoch\": 10,\n",
    "          \"optimizer\": 'SGD',\n",
    "          \"lr\": 0.01\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 10,\n",
    "          \"optimizer\": 'RMSProp',\n",
    "          \"lr\": 0.00001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 10,\n",
    "          \"optimizer\": 'RMSProp',\n",
    "          \"lr\": 0.00001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 20,\n",
    "          \"optimizer\": 'Adam',\n",
    "          \"lr\": 0.00001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 20,\n",
    "          \"optimizer\": 'Adam',\n",
    "          \"lr\": 0.001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 20,\n",
    "          \"optimizer\": 'SGD',\n",
    "          \"lr\": 0.001\n",
    "       }, \n",
    "       {\n",
    "          \"epoch\": 20,\n",
    "          \"optimizer\": 'SGD',\n",
    "          \"lr\": 0.01\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 20,\n",
    "          \"optimizer\": 'RMSProp',\n",
    "          \"lr\": 0.00001\n",
    "       },\n",
    "       {\n",
    "          \"epoch\": 20,\n",
    "          \"optimizer\": 'RMSProp',\n",
    "          \"lr\": 0.00001\n",
    "       }\n",
    "]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T05:56:41.482624Z",
     "iopub.status.busy": "2021-11-12T05:56:41.481929Z",
     "iopub.status.idle": "2021-11-12T06:31:54.871626Z",
     "shell.execute_reply": "2021-11-12T06:31:54.870564Z",
     "shell.execute_reply.started": "2021-11-12T05:56:41.482586Z"
    }
   },
   "outputs": [],
   "source": [
    "run_experiments(hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAz9AhHha3pl"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:53:10.963117Z",
     "iopub.status.busy": "2021-11-12T03:53:10.96286Z",
     "iopub.status.idle": "2021-11-12T03:53:10.972788Z",
     "shell.execute_reply": "2021-11-12T03:53:10.972078Z",
     "shell.execute_reply.started": "2021-11-12T03:53:10.963089Z"
    },
    "id": "b2ZQk5uGLZLt"
   },
   "outputs": [],
   "source": [
    "def prediction(model):\n",
    "    #This function is used to obtain predictions on test data and visulaize some predictions\n",
    "    \n",
    "    #Prepare test data\n",
    "    test_filenames = os.listdir(test_dir)\n",
    "    test_df = pd.DataFrame({\n",
    "      'filename': test_filenames\n",
    "    })\n",
    "    nb_samples = test_df.shape[0]\n",
    "    test_gen = ImageDataGenerator(rescale=1./255.)\n",
    "    test_generator = test_gen.flow_from_dataframe(\n",
    "      test_df, \n",
    "      test_dir, \n",
    "      x_col='filename',\n",
    "      y_col=None,\n",
    "      class_mode=None,\n",
    "      target_size=(224,224),\n",
    "      batch_size=1,\n",
    "      shuffle=False\n",
    "    )\n",
    "  \n",
    "    #prediction\n",
    "    predict = model.predict(test_generator, steps=np.ceil(nb_samples))\n",
    "    threshold = 0.5\n",
    "    test_df['category'] = np.where(predict > threshold, 1,0)\n",
    "\n",
    "    #visualize predictions\n",
    "    sample_test = test_df.head(18)\n",
    "    sample_test.head()\n",
    "    plt.figure(figsize=(12, 24))\n",
    "    for index, row in sample_test.iterrows():\n",
    "        filename = row['filename']\n",
    "        category = row['category']\n",
    "        img = load_img(test_dir+'/'+filename, target_size=(224,224))\n",
    "        ax = plt.subplot(6, 3, index+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(filename + '(' + \"{}\".format(category) + ')' )\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sb.countplot(test_df['category'])\n",
    "    plt.title(\"(Test data)\")\n",
    "  \n",
    "    return test_df \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the best model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:54:04.393091Z",
     "iopub.status.busy": "2021-11-12T03:54:04.392837Z",
     "iopub.status.idle": "2021-11-12T03:54:10.811441Z",
     "shell.execute_reply": "2021-11-12T03:54:10.810339Z",
     "shell.execute_reply.started": "2021-11-12T03:54:04.393061Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model('../input/vgg-adam-94/VGG_hp_2 (1).h5')\n",
    "test_df = prediction(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eiVgr56DbIXN"
   },
   "source": [
    "# Submission.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:55:20.833072Z",
     "iopub.status.busy": "2021-11-12T03:55:20.832801Z",
     "iopub.status.idle": "2021-11-12T03:55:20.849967Z",
     "shell.execute_reply": "2021-11-12T03:55:20.849016Z",
     "shell.execute_reply.started": "2021-11-12T03:55:20.833042Z"
    },
    "id": "vrCqxscQuRd1"
   },
   "outputs": [],
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['id'] = submission_df['filename'].str.split('.').str[0]\n",
    "submission_df['label'] = submission_df['category']\n",
    "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
    "submission_df = submission_df.astype({'id': 'int64'})\n",
    "submission_df.sort_values(by = 'id', inplace=True)\n",
    "submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:55:27.619923Z",
     "iopub.status.busy": "2021-11-12T03:55:27.619667Z",
     "iopub.status.idle": "2021-11-12T03:55:31.166153Z",
     "shell.execute_reply": "2021-11-12T03:55:31.165398Z",
     "shell.execute_reply.started": "2021-11-12T03:55:27.619896Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "validation_dataset = validation_datagen.flow_from_directory(val_dir,\n",
    "                                                      target_size=(224, 224),\n",
    "                                                      batch_size=1,\n",
    "                                                      class_mode='binary',\n",
    "                                                      seed =123,\n",
    "                                                      shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:55:35.112622Z",
     "iopub.status.busy": "2021-11-12T03:55:35.111913Z",
     "iopub.status.idle": "2021-11-12T03:56:07.324358Z",
     "shell.execute_reply": "2021-11-12T03:56:07.323605Z",
     "shell.execute_reply.started": "2021-11-12T03:55:35.112582Z"
    }
   },
   "outputs": [],
   "source": [
    "val_labels = validation_dataset.labels\n",
    "filenames=validation_dataset.filenames\n",
    "    \n",
    "preds = model.predict(validation_dataset)\n",
    "    \n",
    "val_pred_labels = np.where(preds > 0.5, 1,0)\n",
    "val_pred_labels = val_pred_labels.transpose()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:56:11.287413Z",
     "iopub.status.busy": "2021-11-12T03:56:11.284174Z",
     "iopub.status.idle": "2021-11-12T03:56:11.30304Z",
     "shell.execute_reply": "2021-11-12T03:56:11.302311Z",
     "shell.execute_reply.started": "2021-11-12T03:56:11.287358Z"
    }
   },
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12, 6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0, 2, 3, 1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "        \n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([load_img(val_dir+'/' + filenames[i]) for i in idx], titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the correct predictions from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:56:15.190077Z",
     "iopub.status.busy": "2021-11-12T03:56:15.189418Z",
     "iopub.status.idle": "2021-11-12T03:56:15.507882Z",
     "shell.execute_reply": "2021-11-12T03:56:15.507129Z",
     "shell.execute_reply.started": "2021-11-12T03:56:15.190039Z"
    }
   },
   "outputs": [],
   "source": [
    "n_view = 4\n",
    "correct = np.where(val_pred_labels==val_labels)[1]\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, val_pred_labels[0][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the misclassified predictions from validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T03:56:43.336981Z",
     "iopub.status.busy": "2021-11-12T03:56:43.334594Z",
     "iopub.status.idle": "2021-11-12T03:56:43.817817Z",
     "shell.execute_reply": "2021-11-12T03:56:43.816198Z",
     "shell.execute_reply.started": "2021-11-12T03:56:43.336938Z"
    }
   },
   "outputs": [],
   "source": [
    "n_view = 4\n",
    "incorrect = np.where(val_pred_labels!=val_labels)[1]\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, val_pred_labels[0][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T08:37:20.889829Z",
     "iopub.status.busy": "2021-11-12T08:37:20.889321Z",
     "iopub.status.idle": "2021-11-12T08:37:21.659733Z",
     "shell.execute_reply": "2021-11-12T08:37:21.658948Z",
     "shell.execute_reply.started": "2021-11-12T08:37:20.88979Z"
    }
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T08:37:21.661617Z",
     "iopub.status.busy": "2021-11-12T08:37:21.661367Z",
     "iopub.status.idle": "2021-11-12T08:37:23.031803Z",
     "shell.execute_reply": "2021-11-12T08:37:23.030901Z",
     "shell.execute_reply.started": "2021-11-12T08:37:21.661583Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i in range(36):\n",
    "    plt.subplot(6,6,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i])\n",
    "    plt.xlabel(labels[trainY[i][0]],fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T08:37:26.593716Z",
     "iopub.status.busy": "2021-11-12T08:37:26.593459Z",
     "iopub.status.idle": "2021-11-12T08:37:27.013532Z",
     "shell.execute_reply": "2021-11-12T08:37:27.012618Z",
     "shell.execute_reply.started": "2021-11-12T08:37:26.593688Z"
    }
   },
   "outputs": [],
   "source": [
    "# one hot encode target values\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)\n",
    "   \n",
    "# prepare pixel data\n",
    "trainX = trainX.astype('float32')\n",
    "testX = testX.astype('float32')\n",
    "# normalize to range 0-1\n",
    "trainX = trainX / 255.0\n",
    "testX = testX / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T08:37:30.006609Z",
     "iopub.status.busy": "2021-11-12T08:37:30.005849Z",
     "iopub.status.idle": "2021-11-12T08:37:30.017441Z",
     "shell.execute_reply": "2021-11-12T08:37:30.016391Z",
     "shell.execute_reply.started": "2021-11-12T08:37:30.00656Z"
    }
   },
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    # compile model\n",
    "    opt = 'adam'\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:47:54.168937Z",
     "iopub.status.busy": "2021-11-12T09:47:54.167999Z",
     "iopub.status.idle": "2021-11-12T09:47:54.179972Z",
     "shell.execute_reply": "2021-11-12T09:47:54.179188Z",
     "shell.execute_reply.started": "2021-11-12T09:47:54.168887Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    #Plot accuracy \n",
    "    plt.plot(epochs, acc, label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.margins(0.05, tight=True)\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    #Plot Loss\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(epochs, loss, label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.margins(0.05, tight=True)\n",
    "    \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentaion and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T10:08:40.50368Z",
     "iopub.status.busy": "2021-11-12T10:08:40.502884Z",
     "iopub.status.idle": "2021-11-12T10:09:01.060303Z",
     "shell.execute_reply": "2021-11-12T10:09:01.053315Z",
     "shell.execute_reply.started": "2021-11-12T10:08:40.503644Z"
    }
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "model = define_model()\n",
    "\n",
    "# create data generator\n",
    "datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "# prepare iterator\n",
    "train_ds = datagen.flow(trainX, trainY, batch_size=64)\n",
    "# fit model\n",
    "steps = int(trainX.shape[0] / 64)\n",
    "history = model.fit(train_ds, steps_per_epoch=steps, epochs=80, validation_data=(testX, testY))\n",
    "model.save('./Cifar-10.h5')\n",
    "plot_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:54:04.839822Z",
     "iopub.status.busy": "2021-11-12T09:54:04.839054Z",
     "iopub.status.idle": "2021-11-12T09:54:13.910574Z",
     "shell.execute_reply": "2021-11-12T09:54:13.909701Z",
     "shell.execute_reply.started": "2021-11-12T09:54:04.83978Z"
    }
   },
   "outputs": [],
   "source": [
    "scores1 = model.evaluate(testX, testY)\n",
    "scores2 = model.evaluate(trainX, trainY)\n",
    "print('Test loss:', scores1[0])\n",
    "print('Test accuracy:', scores1[1])\n",
    "print('Training loss:', scores2[0])\n",
    "print('Training accuracy:', scores2[1])\n",
    "\n",
    "# make prediction.\n",
    "pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:22:07.816975Z",
     "iopub.status.busy": "2021-11-12T09:22:07.816695Z",
     "iopub.status.idle": "2021-11-12T09:22:07.829036Z",
     "shell.execute_reply": "2021-11-12T09:22:07.828261Z",
     "shell.execute_reply.started": "2021-11-12T09:22:07.816935Z"
    }
   },
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \n",
    "    #This function is used to create a heatmap from a numpy array and two lists of labels.\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "    \n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    \n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label') \n",
    "    ax.set_ylabel('True Label')\n",
    "    \n",
    "    return im, cbar\n",
    "\n",
    "def annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n",
    "    #This function is used to annotate a heatmap.\n",
    "    \n",
    "    # Change the text's color depending on the data.\n",
    "    texts = []\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n",
    "                                 color=\"white\" if data[i, j] > thresh else \"black\")\n",
    "            texts.append(text)\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:22:07.831825Z",
     "iopub.status.busy": "2021-11-12T09:22:07.831336Z",
     "iopub.status.idle": "2021-11-12T09:22:08.702378Z",
     "shell.execute_reply": "2021-11-12T09:22:08.701588Z",
     "shell.execute_reply.started": "2021-11-12T09:22:07.831787Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_pred_classes = np.argmax(pred, axis=1) \n",
    "# Convert validation observations to one hot vectors\n",
    "Y_true = np.argmax(testY, axis=1)\n",
    "# Errors are difference between predicted labels and true labels\n",
    "\n",
    "cm = confusion_matrix(Y_true, Y_pred_classes) \n",
    "thresh = cm.max() / 2.\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "im, cbar = heatmap(cm, labels, labels, ax=ax,\n",
    "                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\n",
    "texts = annotate_heatmap(im, data=cm, threshold=thresh)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:22:08.704518Z",
     "iopub.status.busy": "2021-11-12T09:22:08.703581Z",
     "iopub.status.idle": "2021-11-12T09:22:08.732887Z",
     "shell.execute_reply": "2021-11-12T09:22:08.732136Z",
     "shell.execute_reply.started": "2021-11-12T09:22:08.704475Z"
    }
   },
   "outputs": [],
   "source": [
    "print(classification_report(Y_true, Y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visulaization of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:33:16.240563Z",
     "iopub.status.busy": "2021-11-12T09:33:16.240279Z",
     "iopub.status.idle": "2021-11-12T09:33:17.01946Z",
     "shell.execute_reply": "2021-11-12T09:33:17.018101Z",
     "shell.execute_reply.started": "2021-11-12T09:33:16.240533Z"
    }
   },
   "outputs": [],
   "source": [
    "R = 3\n",
    "C = 5\n",
    "fig, axes = plt.subplots(R, C, figsize=(12,8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, R*C):\n",
    "    axes[i].imshow(testX[i])\n",
    "    axes[i].set_title(\"True: %s \\nPredict: %s\" % (labels[Y_true[i]], labels[Y_pred_classes[i]]))\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-12T09:22:10.363501Z",
     "iopub.status.busy": "2021-11-12T09:22:10.362829Z",
     "iopub.status.idle": "2021-11-12T09:22:11.42087Z",
     "shell.execute_reply": "2021-11-12T09:22:11.420126Z",
     "shell.execute_reply.started": "2021-11-12T09:22:10.363466Z"
    }
   },
   "outputs": [],
   "source": [
    "R = 3\n",
    "C = 5\n",
    "fig, axes = plt.subplots(R, C, figsize=(12,8))\n",
    "axes = axes.ravel()\n",
    "\n",
    "misclassified_idx = np.where(Y_pred_classes != Y_true)[0]\n",
    "for i in np.arange(0, R*C):\n",
    "    axes[i].imshow(testX[misclassified_idx[i]])\n",
    "    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[Y_true[misclassified_idx[i]]], \n",
    "                                                  labels[Y_pred_classes[misclassified_idx[i]]]))\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
